{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd0c569cd2e17f62341e0f08a54f9a867c3c0d3a6f67454072d7de41a8b5dff8343",
   "display_name": "Python 3.9.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# IT - 542 Assignment - 7"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import operator\n",
    "import math\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "source": [
    "## (1) Implement Fuzzy c-means clustering algorithm. Use IRIS data to evaluate performance of the algorithm. Compare your results with that of the in-built function."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(150, 4)\n(150,)\n"
     ]
    }
   ],
   "source": [
    "# Load IRIS dataset\n",
    "iris_data, iris_labels = load_iris(return_X_y=True)\n",
    "print(iris_data.shape)\n",
    "print(iris_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy function for IRIS data\n",
    "def accuracy_iris(cluster_labels, target_labels):\n",
    "    # correct_pred = 0\n",
    "    # for i in range(len(cluster_labels)):\n",
    "    #     if cluster_labels[i] == target_labels[i]: correct_pred += 1\n",
    "    correct_pred = np.where(cluster_labels == target_labels)[0]\n",
    "    \n",
    "    accuracy = (correct_pred.shape[0] / len(cluster_labels)) * 100\n",
    "    return accuracy"
   ]
  },
  {
   "source": [
    "### Custom implementation of Fuzzy C-Means"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FuzzyCMeans:\n",
    "\n",
    "    def __init__(self, n_clusters, m=2, max_iter=300):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.m = m\n",
    "        self.max_iter = max_iter\n",
    "        self.member_mat = None\n",
    "        self.cluster_centers = []\n",
    "        self.cluster_labels = []\n",
    "    \n",
    "\n",
    "    def init_membership_matrix(self):\n",
    "        self.member_mat = np.zeros((self.n, self.n_clusters))\n",
    "        for i in range(self.n):\n",
    "            random.seed(202011032)\n",
    "            init_mem_list = [np.random.random() for _ in range(self.n_clusters)]\n",
    "            summation = sum(init_mem_list)\n",
    "            init_mem_list = [x / summation for x in init_mem_list]\n",
    "            \n",
    "            flag = init_mem_list.index(max(init_mem_list))\n",
    "            for j in range(0, len(init_mem_list)):\n",
    "                if(j == flag):\n",
    "                    init_mem_list[j] = 1\n",
    "                else:\n",
    "                    init_mem_list[j] = 0\n",
    "            \n",
    "            self.member_mat[i] = np.array(init_mem_list)\n",
    "\n",
    "        # return member_mat\n",
    "    \n",
    "\n",
    "    def calculate_cluster_centers(self, data):\n",
    "        clusters = self.member_mat.T\n",
    "        self.cluster_centers = []\n",
    "        for j in range(self.n_clusters):\n",
    "            x = clusters[j]\n",
    "            # x_raised = [p ** self.m for p in x]\n",
    "            x_raised = np.power(x, self.m)\n",
    "            denominator = sum(x_raised)\n",
    "            temp_num = []\n",
    "            # temp_num = np.multiply(data, x_raised)\n",
    "            for i in range(self.n):\n",
    "                data_point = data[i]\n",
    "                # prod = data[i] * x_raised[i]\n",
    "                prod = [x_raised[i] * val for val in data_point]\n",
    "                temp_num.append(prod)\n",
    "            # numerator = list(map(sum, list(zip(*temp_num))))\n",
    "            numerator = np.sum(np.array(temp_num).T, axis=1)\n",
    "            center = numerator / denominator\n",
    "            self.cluster_centers.append(center)\n",
    "        # return cluster_centers\n",
    "    \n",
    "\n",
    "    def update_member_mat(self, data):\n",
    "        p = float(2 / (self.m - 1))\n",
    "        for i in range(self.n):\n",
    "            x = data[i]\n",
    "            distances = [np.linalg.norm(np.array(list(map(operator.sub, data[i], self.cluster_centers[j])))) for j in range(self.n_clusters)]\n",
    "            for j in range(self.n_clusters):\n",
    "                denom = sum([math.pow(float(distances[j] / distances[c]), p) for c in range(self.n_clusters)])\n",
    "                self.member_mat[i, j] = float(1 / denom)       \n",
    "        # return member_mat\n",
    "    \n",
    "    \n",
    "    def get_clusters(self):\n",
    "        self.cluster_labels = []\n",
    "        for i in range(self.n):\n",
    "            max_val, label = max((val, idx) for (idx, val) in enumerate(self.member_mat[i]))\n",
    "            self.cluster_labels.append(label)\n",
    "        # return cluster_labels\n",
    "    \n",
    "\n",
    "    def fit(self, data):\n",
    "        self.n = np.array(data).shape[0]\n",
    "        self.init_membership_matrix()\n",
    "        acc = []\n",
    "        for curr in range(self.max_iter):\n",
    "            self.calculate_cluster_centers(data)\n",
    "            self.update_member_mat(data)\n",
    "            self.get_clusters()\n",
    "            \n",
    "            acc.append(self.cluster_labels)\n",
    "            \n",
    "            if(curr == 0):\n",
    "                print(\"Initial Cluster Centers:\")\n",
    "                print(np.array(self.cluster_centers))\n",
    "\n",
    "        print(\"---------------------------\")\n",
    "        print(\"Partition matrix:\")\n",
    "        print(np.around(self.member_mat, decimals=4))\n",
    "        #return cluster_labels, cluster_centers\n",
    "        return self.cluster_labels, self.cluster_centers, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Initial Cluster Centers:\n",
      "[[5.72909091 3.08       3.47272727 1.05818182]\n",
      " [5.86909091 3.00363636 3.91818182 1.28545455]\n",
      " [5.965      3.1        3.93       1.275     ]]\n",
      "---------------------------\n",
      "Partition matrix:\n",
      "[[0.9198 0.0471 0.033 ]\n",
      " [0.8226 0.1049 0.0725]\n",
      " [0.8335 0.0978 0.0687]\n",
      " [0.7983 0.1193 0.0824]\n",
      " [0.9002 0.0586 0.0412]\n",
      " [0.7279 0.1604 0.1117]\n",
      " [0.8315 0.0991 0.0694]\n",
      " [0.9726 0.0162 0.0112]\n",
      " [0.7251 0.162  0.113 ]\n",
      " [0.8471 0.0905 0.0623]\n",
      " [0.7947 0.1206 0.0847]\n",
      " [0.8916 0.0642 0.0442]\n",
      " [0.8069 0.114  0.0791]\n",
      " [0.7122 0.1676 0.1202]\n",
      " [0.6667 0.1921 0.1413]\n",
      " [0.6186 0.2196 0.1618]\n",
      " [0.7475 0.147  0.1056]\n",
      " [0.9202 0.047  0.0328]\n",
      " [0.6856 0.1852 0.1291]\n",
      " [0.8268 0.1017 0.0715]\n",
      " [0.8002 0.119  0.0808]\n",
      " [0.8487 0.0891 0.0622]\n",
      " [0.7719 0.1321 0.096 ]\n",
      " [0.8352 0.0987 0.0661]\n",
      " [0.798  0.1209 0.0811]\n",
      " [0.8175 0.1088 0.0737]\n",
      " [0.9115 0.0526 0.0359]\n",
      " [0.8952 0.0619 0.043 ]\n",
      " [0.8978 0.0602 0.042 ]\n",
      " [0.8353 0.0978 0.067 ]\n",
      " [0.8335 0.099  0.0675]\n",
      " [0.8149 0.1096 0.0755]\n",
      " [0.7328 0.1554 0.1118]\n",
      " [0.6834 0.183  0.1336]\n",
      " [0.8572 0.0847 0.0581]\n",
      " [0.8522 0.0867 0.0611]\n",
      " [0.7854 0.1256 0.089 ]\n",
      " [0.8779 0.0716 0.0505]\n",
      " [0.7394 0.1529 0.1076]\n",
      " [0.9455 0.0322 0.0223]\n",
      " [0.9025 0.0572 0.0403]\n",
      " [0.6325 0.2163 0.1511]\n",
      " [0.7626 0.1391 0.0983]\n",
      " [0.8314 0.1002 0.0684]\n",
      " [0.7481 0.1501 0.1018]\n",
      " [0.8114 0.1116 0.077 ]\n",
      " [0.8197 0.1061 0.0742]\n",
      " [0.816  0.1084 0.0756]\n",
      " [0.821  0.1052 0.0738]\n",
      " [0.9305 0.041  0.0285]\n",
      " [0.128  0.419  0.453 ]\n",
      " [0.1077 0.5808 0.3115]\n",
      " [0.1082 0.3811 0.5107]\n",
      " [0.1584 0.6291 0.2125]\n",
      " [0.0991 0.5762 0.3247]\n",
      " [0.0636 0.8079 0.1285]\n",
      " [0.1057 0.5264 0.3678]\n",
      " [0.3228 0.45   0.2273]\n",
      " [0.111  0.5525 0.3365]\n",
      " [0.1854 0.5957 0.219 ]\n",
      " [0.2855 0.4738 0.2407]\n",
      " [0.0736 0.787  0.1394]\n",
      " [0.1621 0.6092 0.2288]\n",
      " [0.0756 0.7015 0.2229]\n",
      " [0.2013 0.5872 0.2115]\n",
      " [0.1263 0.5312 0.3425]\n",
      " [0.0887 0.7277 0.1836]\n",
      " [0.1218 0.7029 0.1753]\n",
      " [0.1134 0.6143 0.2723]\n",
      " [0.1623 0.6382 0.1995]\n",
      " [0.104  0.5495 0.3464]\n",
      " [0.105  0.7235 0.1715]\n",
      " [0.0983 0.5397 0.362 ]\n",
      " [0.0827 0.6992 0.2181]\n",
      " [0.103  0.6656 0.2315]\n",
      " [0.1166 0.571  0.3124]\n",
      " [0.1117 0.4514 0.4369]\n",
      " [0.088  0.3433 0.5687]\n",
      " [0.051  0.8216 0.1275]\n",
      " [0.2313 0.551  0.2177]\n",
      " [0.1902 0.5961 0.2138]\n",
      " [0.2129 0.5684 0.2187]\n",
      " [0.1323 0.6901 0.1776]\n",
      " [0.0964 0.512  0.3915]\n",
      " [0.1156 0.6663 0.2181]\n",
      " [0.1148 0.5992 0.286 ]\n",
      " [0.1107 0.4665 0.4228]\n",
      " [0.1142 0.6344 0.2515]\n",
      " [0.1166 0.7111 0.1724]\n",
      " [0.1446 0.6607 0.1947]\n",
      " [0.1091 0.7079 0.183 ]\n",
      " [0.0741 0.7243 0.2017]\n",
      " [0.1176 0.7133 0.1691]\n",
      " [0.3145 0.457  0.2285]\n",
      " [0.0945 0.7554 0.1501]\n",
      " [0.0991 0.7434 0.1575]\n",
      " [0.0808 0.7861 0.1331]\n",
      " [0.0775 0.7581 0.1644]\n",
      " [0.3579 0.4234 0.2187]\n",
      " [0.0933 0.7632 0.1436]\n",
      " [0.0999 0.2517 0.6484]\n",
      " [0.1058 0.487  0.4072]\n",
      " [0.0756 0.1914 0.7331]\n",
      " [0.0716 0.2445 0.6838]\n",
      " [0.0564 0.1604 0.7832]\n",
      " [0.1344 0.2809 0.5847]\n",
      " [0.1744 0.5482 0.2774]\n",
      " [0.1126 0.2604 0.627 ]\n",
      " [0.0854 0.2492 0.6654]\n",
      " [0.1171 0.2563 0.6266]\n",
      " [0.0777 0.2812 0.6411]\n",
      " [0.076  0.2898 0.6341]\n",
      " [0.026  0.0773 0.8967]\n",
      " [0.1164 0.5063 0.3773]\n",
      " [0.1187 0.4126 0.4687]\n",
      " [0.0751 0.2372 0.6877]\n",
      " [0.0526 0.1783 0.7691]\n",
      " [0.1528 0.2953 0.5519]\n",
      " [0.1504 0.2996 0.5501]\n",
      " [0.1152 0.5355 0.3492]\n",
      " [0.0616 0.1615 0.7769]\n",
      " [0.1162 0.5324 0.3515]\n",
      " [0.1422 0.292  0.5658]\n",
      " [0.0921 0.48   0.4279]\n",
      " [0.0509 0.141  0.8081]\n",
      " [0.0943 0.2303 0.6753]\n",
      " [0.0908 0.5414 0.3678]\n",
      " [0.093  0.508  0.399 ]\n",
      " [0.0607 0.1935 0.7458]\n",
      " [0.0938 0.2432 0.6629]\n",
      " [0.1085 0.255  0.6366]\n",
      " [0.1528 0.2972 0.55  ]\n",
      " [0.0639 0.1987 0.7373]\n",
      " [0.0927 0.4567 0.4506]\n",
      " [0.1091 0.3903 0.5006]\n",
      " [0.1244 0.269  0.6066]\n",
      " [0.0895 0.2478 0.6627]\n",
      " [0.0619 0.2116 0.7265]\n",
      " [0.0935 0.5679 0.3386]\n",
      " [0.0467 0.1365 0.8168]\n",
      " [0.0588 0.162  0.7792]\n",
      " [0.0831 0.2446 0.6722]\n",
      " [0.1058 0.487  0.4072]\n",
      " [0.0694 0.178  0.7526]\n",
      " [0.0786 0.2029 0.7185]\n",
      " [0.069  0.2151 0.7159]\n",
      " [0.0976 0.4361 0.4663]\n",
      " [0.0646 0.2366 0.6988]\n",
      " [0.0937 0.2814 0.6249]\n",
      " [0.0997 0.4731 0.4272]]\n"
     ]
    }
   ],
   "source": [
    "# Fit the IRIS data\n",
    "fuzzy_cmeans_clusterer = FuzzyCMeans(n_clusters=3, m=3, max_iter=500)\n",
    "cluster_labels, cluster_centers, acc = fuzzy_cmeans_clusterer.fit(iris_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cluster labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2 1 2 2 2 2\n 2 2 1 2 2 2 2 2 1 2 1 2 1 2 2 1 1 2 2 2 2 2 1 2 2 2 2 1 2 2 2 1 2 2 2 2 2\n 2 1]\nAccuracy: 90.000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cluster labels: {np.array(cluster_labels)}\")\n",
    "a = accuracy_iris(cluster_labels, iris_labels)\n",
    "print(f\"Accuracy: {a:.3f}\")"
   ]
  },
  {
   "source": [
    "### Using `scikit-fuzzy` library for Fuzzy C-Means"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[5.00267073 3.40360833 1.49178815 0.25413933]\n [5.9108032  2.79154751 4.3795376  1.39688394]\n [6.69468326 3.03733703 5.55115454 2.03535714]]\n-----------------------------\nPartition Matrix:\n[[0.91983125 0.04713757 0.03303118]\n [0.82268509 0.10485733 0.07245759]\n [0.83351346 0.09780365 0.06868289]\n [0.7983921  0.11923264 0.08237526]\n [0.90018416 0.05857425 0.04124159]\n [0.72796977 0.16035862 0.1116716 ]\n [0.83151023 0.09905207 0.06943769]\n [0.97263616 0.01616834 0.0111955 ]\n [0.72514792 0.16188617 0.11296591]\n [0.84718095 0.09049489 0.06232416]\n [0.79474822 0.120548   0.08470378]\n [0.89165831 0.06416299 0.0441787 ]\n [0.80691377 0.11397529 0.07911094]\n [0.71229528 0.16752635 0.12017837]\n [0.66668557 0.19200574 0.14130869]\n [0.61866522 0.21952071 0.16181407]\n [0.74748282 0.14692228 0.1055949 ]\n [0.92018609 0.04697529 0.03283862]\n [0.68566631 0.18517648 0.12915721]\n [0.8268296  0.10163686 0.07153354]\n [0.80023347 0.11892934 0.08083718]\n [0.84867738 0.08909024 0.06223239]\n [0.77192695 0.13204221 0.09603083]\n [0.83529917 0.09859721 0.06610362]\n [0.79807743 0.12086458 0.08105799]\n [0.81754503 0.10876495 0.07369002]\n [0.91152952 0.05257995 0.03589053]\n [0.89517604 0.06184956 0.0429744 ]\n [0.8977734  0.06020811 0.04201849]\n [0.83531208 0.09772673 0.06696119]\n [0.83354587 0.0989855  0.06746862]\n [0.81496018 0.10956071 0.07547911]\n [0.7328342  0.15533494 0.11183086]\n [0.6834794  0.18294859 0.13357201]\n [0.85723653 0.08465203 0.05811145]\n [0.85226915 0.08662621 0.06110465]\n [0.78540283 0.1256053  0.08899187]\n [0.87788632 0.07156001 0.05055367]\n [0.73950045 0.15286282 0.10763673]\n [0.94548804 0.03221807 0.02229389]\n [0.90255274 0.05714872 0.04029854]\n [0.63261088 0.21624503 0.15114409]\n [0.76261806 0.13905727 0.09832467]\n [0.83141928 0.10014792 0.0684328 ]\n [0.74813436 0.15002118 0.10184446]\n [0.81149695 0.1115194  0.07698365]\n [0.81974164 0.10603156 0.0742268 ]\n [0.81601789 0.10833779 0.07564432]\n [0.82099477 0.10517385 0.07383138]\n [0.93051936 0.04097152 0.02850912]\n [0.12792433 0.41923489 0.45284077]\n [0.10755939 0.58126032 0.3111803 ]\n [0.10813681 0.38142343 0.51043976]\n [0.15864288 0.62853626 0.21282087]\n [0.09891555 0.57676799 0.32431645]\n [0.0637013  0.80755303 0.12874567]\n [0.10557824 0.52691834 0.36750342]\n [0.32292073 0.44966906 0.22741021]\n [0.1108278  0.55294304 0.33622916]\n [0.18558991 0.59513987 0.21927022]\n [0.28565311 0.47350399 0.24084289]\n [0.07367942 0.78672069 0.1395999 ]\n [0.16220036 0.60881696 0.22898269]\n [0.07533283 0.70240175 0.22226542]\n [0.20151012 0.58667244 0.21181744]\n [0.12620376 0.5315421  0.34225414]\n [0.08867885 0.72760782 0.18371333]\n [0.12201648 0.70223254 0.17575097]\n [0.113333   0.614461   0.272206  ]\n [0.16255641 0.63762605 0.19981754]\n [0.10390514 0.54992774 0.34616712]\n [0.10514747 0.72312883 0.1717237 ]\n [0.09820644 0.54010968 0.36168389]\n [0.082509   0.69978999 0.21770101]\n [0.10283753 0.66589584 0.23126664]\n [0.11648783 0.57140649 0.31210568]\n [0.1115994  0.45171992 0.43668068]\n [0.08796292 0.34359534 0.56844174]\n [0.0506219  0.82272353 0.12665457]\n [0.23156072 0.55051787 0.21792141]\n [0.19041335 0.59553247 0.21405417]\n [0.21308753 0.56793539 0.21897707]\n [0.13257232 0.68938297 0.17804471]\n [0.09632792 0.51245551 0.39121657]\n [0.11569047 0.66606348 0.21824605]\n [0.1146893  0.59946867 0.28584203]\n [0.11058575 0.46688789 0.42252636]\n [0.11412072 0.63444745 0.25143183]\n [0.11681547 0.71038686 0.17279766]\n [0.14490297 0.66004526 0.19505177]\n [0.10930246 0.70735842 0.18333912]\n [0.07381058 0.72514432 0.2010451 ]\n [0.1178969  0.71258549 0.16951761]\n [0.31466071 0.4567247  0.22861459]\n [0.09483523 0.75453496 0.15062981]\n [0.09935835 0.74271603 0.15792562]\n [0.08110697 0.7852071  0.13368593]\n [0.07740005 0.75838348 0.16421647]\n [0.35807206 0.42306905 0.21885889]\n [0.09364652 0.76221615 0.14413732]\n [0.09985609 0.25189311 0.64825079]\n [0.10567036 0.48727216 0.40705748]\n [0.07558777 0.19161836 0.73279386]\n [0.07158566 0.24465963 0.68375471]\n [0.0563844  0.16053805 0.78307755]\n [0.13439942 0.28112725 0.58447332]\n [0.17446224 0.5479508  0.27758696]\n [0.11258376 0.26062153 0.6267947 ]\n [0.08538083 0.24942924 0.66518993]\n [0.11712201 0.25652913 0.62634886]\n [0.07762956 0.28137518 0.64099526]\n [0.07594364 0.29001131 0.63404505]\n [0.02603336 0.07744392 0.89652271]\n [0.11628961 0.50648901 0.37722139]\n [0.11861244 0.41279733 0.46859024]\n [0.07505743 0.23730564 0.68763693]\n [0.05252667 0.17839228 0.76908105]\n [0.15275963 0.29549242 0.55174795]\n [0.15035113 0.29972765 0.54992122]\n [0.1151683  0.53570839 0.34912331]\n [0.06162543 0.1617953  0.77657927]\n [0.11610382 0.53253555 0.35136062]\n [0.14215168 0.29219544 0.56565287]\n [0.09198361 0.48043529 0.4275811 ]\n [0.05091199 0.14124247 0.80784553]\n [0.09433867 0.23057973 0.6750816 ]\n [0.09061941 0.54199962 0.36738097]\n [0.09286541 0.50854026 0.39859432]\n [0.06070018 0.19353556 0.74576426]\n [0.09380654 0.24349173 0.66270174]\n [0.10847296 0.25518281 0.63634422]\n [0.15278962 0.29740301 0.54980737]\n [0.06390535 0.19883204 0.73726261]\n [0.0925603  0.45716466 0.45027503]\n [0.10902227 0.39050239 0.50047533]\n [0.12441978 0.2691804  0.60639983]\n [0.08949273 0.24796199 0.66254528]\n [0.06188568 0.21166678 0.72644754]\n [0.09333638 0.56844224 0.33822137]\n [0.04668112 0.13669073 0.81662815]\n [0.05879542 0.16218984 0.77901474]\n [0.08311886 0.24483896 0.67204218]\n [0.10567036 0.48727216 0.40705748]\n [0.06946752 0.17823079 0.75230169]\n [0.07860252 0.20307886 0.71831861]\n [0.0689706  0.21519844 0.71583096]\n [0.09751031 0.43638479 0.4661049 ]\n [0.06454256 0.23672784 0.6987296 ]\n [0.09362827 0.28153216 0.62483957]\n [0.09962609 0.47345607 0.42691784]]\n"
     ]
    }
   ],
   "source": [
    "import skfuzzy as fuzz\n",
    "\n",
    "cl_centers, u_orig, _, _, _, _, _ = fuzz.cluster.cmeans(iris_data.T, 3, 3, error=0.005, maxiter=500)\n",
    "print(cl_centers)\n",
    "print(\"-----------------------------\")\n",
    "print(\"Partition Matrix:\")\n",
    "print(np.array([[a, b, c] for a, b, c in zip(u_orig[0], u_orig[1], u_orig[2])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-----------------------------\nCluster labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2 1 2 2 2 2\n 2 2 1 2 2 2 2 2 1 2 1 2 1 2 2 1 1 2 2 2 2 2 1 2 2 2 2 1 2 2 2 1 2 2 2 2 2\n 2 1]\nAccuracy: 90.0\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------------\")\n",
    "print(f\"Cluster labels: {np.argmax(u_orig, axis=0)}\")\n",
    "print(f\"Accuracy: {accuracy_iris(np.argmax(u_orig, axis=0), iris_labels)}\")"
   ]
  },
  {
   "source": [
    "## (2)  Implement Agglomerative clustering algorithm. Use IRIS data to evaluate performance of the algorithm. Compare your results with that of the in-built function."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Custom implementation of Agglomerative clustering"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAgglomerativeClustering:\n",
    "    # By default uses euclidean distance measure\n",
    "    def __init__(self, n_clusters: int = 2, linkage: str = 'single'):\n",
    "        self.n_clusters_ = n_clusters\n",
    "        self.labels_ = []\n",
    "        self.__linkage = linkage\n",
    "        self.__clusters = []\n",
    "    \n",
    "\n",
    "    def __single_linkage(self, data):\n",
    "        # Every data point is a cluster at initial\n",
    "        self.__clusters = np.expand_dims(data, axis=1).tolist()\n",
    "\n",
    "        while len(self.__clusters) != self.n_clusters_:\n",
    "            \n",
    "            min_distance = cl_1 = cl_2 = math.inf\n",
    "            # for every cluster (until second last element)\n",
    "            for cl_idx, cluster in enumerate(self.__clusters[:-1]):\n",
    "                # for each point in each cluster\n",
    "                for point_id, point in enumerate(cluster): \n",
    "                    # compare with clusters after the current one\n",
    "                    for cl_idx_2, cluster2 in enumerate(self.__clusters[(cl_idx + 1):]):\n",
    "                        # go through every point in this prospective cluster as well\n",
    "                        for point2_id, point2 in enumerate(cluster2):\n",
    "                            # Check distance using single linkage and euclidean distance\n",
    "                            clust_diff = np.array(point) - np.array(point2)\n",
    "                            if np.linalg.norm(clust_diff) < min_distance:  \n",
    "                                min_distance = np.linalg.norm(clust_diff)\n",
    "                                # this will be used at the end to figure out which cluster to merge with which\n",
    "                                cl_1 = cl_idx\n",
    "                                # this cluster will be destroyed by the end\n",
    "                                cl_2 = (cl_idx + 1) + cl_idx_2\n",
    "            \n",
    "            # merge clusters\n",
    "            print(cl_1,' | ', cl_2, ' | ', min_distance)\n",
    "            self.__clusters[cl_1].extend(self.__clusters[cl_2])\n",
    "            # remove the cluster which is now merged in another cluster\n",
    "            self.__clusters.pop(cl_2)\n",
    "\n",
    "\n",
    "    def __get_labels(self, data):\n",
    "        # Call after clustering is done, otherwise will raise an error\n",
    "        if len(self.__clusters) == 0:\n",
    "            raise ValueError(\"Clusters list is empty. Run clustering algorithm first.\")\n",
    "\n",
    "        for data_pt in data.tolist():\n",
    "            if data_pt in self.__clusters[0]:\n",
    "                self.labels_.append(0)\n",
    "            elif data_pt in self.__clusters[1]:\n",
    "                self.labels_.append(1)\n",
    "            else:\n",
    "                # data_pt will be in self.__clusters[2]\n",
    "                self.labels_.append(2)\n",
    "\n",
    "\n",
    "    \n",
    "    def fit(self, data: np.ndarray):\n",
    "        if self.__linkage == 'single':\n",
    "            self.__single_linkage(data)\n",
    "        self.__get_labels(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "101  |  142  |  0.0\n",
      "7  |  39  |  0.09999999999999964\n",
      "0  |  17  |  0.09999999999999998\n",
      "9  |  33  |  0.1\n",
      "125  |  129  |  0.10000000000000009\n",
      "10  |  45  |  0.10000000000000053\n",
      "0  |  37  |  0.14142135623730917\n",
      "4  |  35  |  0.14142135623730925\n",
      "18  |  20  |  0.14142135623730928\n",
      "0  |  4  |  0.1414213562373093\n",
      "26  |  27  |  0.1414213562373093\n",
      "48  |  84  |  0.1414213562373093\n",
      "71  |  72  |  0.1414213562373093\n",
      "105  |  125  |  0.1414213562373093\n",
      "7  |  32  |  0.14142135623730948\n",
      "17  |  37  |  0.14142135623730956\n",
      "0  |  6  |  0.14142135623730964\n",
      "0  |  37  |  0.14142135623730964\n",
      "1  |  7  |  0.14142135623730964\n",
      "3  |  35  |  0.14142135623730964\n",
      "22  |  23  |  0.14142135623730964\n",
      "65  |  75  |  0.14142135623730964\n",
      "76  |  77  |  0.14142135623730964\n",
      "107  |  116  |  0.14142135623730964\n",
      "2  |  3  |  0.14142135623730978\n",
      "1  |  32  |  0.14142135623730986\n",
      "1  |  8  |  0.1414213562373099\n",
      "0  |  20  |  0.14142135623730995\n",
      "1  |  20  |  0.14142135623730995\n",
      "42  |  69  |  0.14142135623730995\n",
      "44  |  54  |  0.14142135623730995\n",
      "69  |  72  |  0.14142135623730995\n",
      "95  |  98  |  0.17320508075688762\n",
      "1  |  18  |  0.17320508075688765\n",
      "47  |  57  |  0.17320508075688765\n",
      "82  |  105  |  0.1732050807568879\n",
      "1  |  2  |  0.17320508075688815\n",
      "65  |  66  |  0.17320508075688815\n",
      "62  |  65  |  0.1732050807568884\n",
      "43  |  58  |  0.1999999999999993\n",
      "40  |  54  |  0.19999999999999973\n",
      "15  |  17  |  0.1999999999999998\n",
      "4  |  23  |  0.20000000000000018\n",
      "28  |  59  |  0.20000000000000018\n",
      "49  |  60  |  0.20000000000000018\n",
      "1  |  4  |  0.22360679774997827\n",
      "1  |  5  |  0.22360679774997858\n",
      "1  |  3  |  0.22360679774997871\n",
      "0  |  17  |  0.22360679774997877\n",
      "0  |  3  |  0.22360679774997896\n",
      "11  |  18  |  0.22360679774997896\n",
      "32  |  42  |  0.22360679774997896\n",
      "39  |  80  |  0.22360679774997896\n",
      "0  |  11  |  0.22360679774997902\n",
      "0  |  1  |  0.22360679774997916\n",
      "62  |  92  |  0.22360679774997935\n",
      "72  |  88  |  0.22360679774997935\n",
      "85  |  91  |  0.2449489742783171\n",
      "25  |  32  |  0.24494897427831722\n",
      "20  |  35  |  0.24494897427831766\n",
      "21  |  25  |  0.24494897427831766\n",
      "32  |  41  |  0.24494897427831766\n",
      "71  |  86  |  0.24494897427831774\n",
      "0  |  7  |  0.2449489742783178\n",
      "50  |  63  |  0.24494897427831783\n",
      "80  |  82  |  0.24494897427831785\n",
      "0  |  2  |  0.244948974278318\n",
      "80  |  81  |  0.24494897427831822\n",
      "32  |  68  |  0.24494897427831838\n",
      "30  |  43  |  0.26457513110645864\n",
      "31  |  42  |  0.26457513110645864\n",
      "19  |  35  |  0.2645751311064587\n",
      "44  |  56  |  0.26457513110645897\n",
      "15  |  17  |  0.26457513110645914\n",
      "29  |  40  |  0.26457513110645914\n",
      "17  |  29  |  0.2645751311064592\n",
      "16  |  20  |  0.2645751311064593\n",
      "46  |  64  |  0.26457513110645936\n",
      "57  |  69  |  0.26457513110645947\n",
      "44  |  59  |  0.26457513110645964\n",
      "29  |  69  |  0.282842712474618\n",
      "6  |  9  |  0.282842712474619\n",
      "14  |  36  |  0.2828427124746193\n",
      "0  |  8  |  0.2999999999999998\n",
      "54  |  56  |  0.2999999999999998\n",
      "0  |  10  |  0.3\n",
      "0  |  6  |  0.3000000000000001\n",
      "13  |  19  |  0.3000000000000001\n",
      "47  |  60  |  0.3000000000000001\n",
      "37  |  54  |  0.30000000000000016\n",
      "15  |  22  |  0.30000000000000027\n",
      "33  |  51  |  0.3162277660168375\n",
      "12  |  14  |  0.31622776601683755\n",
      "13  |  14  |  0.3162277660168378\n",
      "11  |  12  |  0.31622776601683783\n",
      "11  |  24  |  0.31622776601683794\n",
      "11  |  23  |  0.31622776601683816\n",
      "12  |  17  |  0.33166247903553975\n",
      "23  |  48  |  0.33166247903553975\n",
      "1  |  5  |  0.33166247903553986\n",
      "18  |  26  |  0.33166247903553997\n",
      "10  |  19  |  0.33166247903554\n",
      "26  |  27  |  0.3316624790355402\n",
      "32  |  33  |  0.34641016151377513\n",
      "33  |  39  |  0.34641016151377513\n",
      "0  |  1  |  0.3464101615137753\n",
      "0  |  3  |  0.3464101615137753\n",
      "8  |  9  |  0.3464101615137753\n",
      "0  |  4  |  0.3464101615137755\n",
      "0  |  4  |  0.3464101615137755\n",
      "34  |  35  |  0.3464101615137756\n",
      "6  |  15  |  0.3464101615137758\n",
      "14  |  15  |  0.3605551275463984\n",
      "0  |  5  |  0.3605551275463988\n",
      "18  |  24  |  0.3605551275463988\n",
      "6  |  8  |  0.3605551275463989\n",
      "11  |  12  |  0.3605551275463989\n",
      "16  |  32  |  0.3605551275463989\n",
      "16  |  22  |  0.360555127546399\n",
      "0  |  2  |  0.3605551275463992\n",
      "15  |  22  |  0.374165738677394\n",
      "4  |  11  |  0.3741657386773941\n",
      "10  |  14  |  0.3741657386773942\n",
      "5  |  11  |  0.3872983346207412\n",
      "4  |  6  |  0.38729833462074165\n",
      "11  |  21  |  0.38729833462074187\n",
      "9  |  11  |  0.3999999999999997\n",
      "11  |  18  |  0.4123105625617659\n",
      "0  |  1  |  0.412310562561766\n",
      "16  |  18  |  0.4123105625617661\n",
      "3  |  8  |  0.4123105625617663\n",
      "3  |  6  |  0.42426406871192834\n",
      "3  |  7  |  0.42426406871192884\n",
      "3  |  14  |  0.43588989435406705\n",
      "3  |  9  |  0.43588989435406733\n",
      "0  |  1  |  0.45825756949558405\n",
      "2  |  10  |  0.4898979485566353\n",
      "2  |  4  |  0.4898979485566356\n",
      "2  |  4  |  0.5099019513592786\n",
      "2  |  4  |  0.5291502622129179\n",
      "2  |  9  |  0.5385164807134504\n",
      "2  |  8  |  0.5385164807134505\n",
      "2  |  5  |  0.5567764362830021\n",
      "0  |  1  |  0.6244997998398398\n",
      "1  |  4  |  0.6324555320336759\n",
      "1  |  2  |  0.6480740698407863\n",
      "1  |  2  |  0.7348469228349535\n"
     ]
    }
   ],
   "source": [
    "agglomerative_clusterer = CustomAgglomerativeClustering(n_clusters=3, linkage='single')\n",
    "agglomerative_clusterer.fit(iris_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\nAccuracy: 68.0\n"
     ]
    }
   ],
   "source": [
    "print(agglomerative_clusterer.labels_)\n",
    "print(f\"Accuracy: {accuracy_iris(agglomerative_clusterer.labels_, iris_labels)}\")"
   ]
  },
  {
   "source": [
    "### Using `sklearn` library's Agglomerative Clustering"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]\nAccuracy: 1.3333333333333335\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "sk_clusterer = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='single')\n",
    "print(sk_clusterer.fit_predict(iris_data))\n",
    "print(f\"Accuracy: {accuracy_iris(sk_clusterer.labels_, iris_labels)}\")"
   ]
  }
 ]
}